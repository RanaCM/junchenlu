---
layout: archive
title: "About Me"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
  - /about/
  - /about.html
  - /
---

{% include base_path %}

Education
======
* Ph.D. in Electrical and Computer Engineering, Aug 2020 - present
  * National University of Singapore, GPA: 4.50/5.00

* M.Sc. in Electrical and Computer Engineering, Aug 2019 - Jul 2020
  * National University of Singapore, GPA: 4.31/5.00

* B.Eng. in Electronic and Information Engineering, Sep 2015 - Jun 2019
  * University of Electronic Science and Technology of China, GPA: 3.83/4.00

Publications
======
* **Junchen Lu**, Berrak Sisman, Mingyang Zhang, Haizhou Li, "High-Quality Automatic Voice Over with Accurate Alignment: Supervision through Self-Supervised Discrete Speech Units," INTERSPEECH 2023, Dublin, Ireland, Aug 2023. [**[code]**](https://github.com/RanaCM/DSU-AVO)

* **Junchen Lu**, Berrak Sisman, Rui Liu, Mingyang Zhang, Haizhou Li, "VisualTTS: TTS with Accurate Lip-Speech Synchronization for Automatic Voice Over," ICASSP 2022, Singapore, May 2022.

* **Junchen Lu**, Kun Zhou, Berrak Sisman, Haizhou Li, "VAW-GAN for Singing Voice Conversion with Non-Parallel Training Data," APSIPA ASC 2020, Auckland, New Zealand, Dec 2020. [**[code]**](https://github.com/RanaCM/Singing-Voice-Conversion-with-Conditional-VAW-GAN)

* Zongyang Du, **Junchen Lu**, Kun Zhou, Berrak Sisman, "Converting Anyone's Voice: End-to-End Expressive Voice Conversion with a Conditional Diffusion Model," under review as a conference paper.

Research experience
======
* Ph.D. Student, Human Language Technology (HLT) Laboratory, Aug 2020 - present
  * Department of Electrical and Computer Engineering, National University of Singapore
  * Research topic: expressive speech synthesis
  * Supervisor: Prof. Haizhou Li
  * Formulated a novel multi-modal speech synthesis task "Automatic Voice Over", broadening the scope of expressiveness in speech synthesis; Integrated visual information into text-to-speech synthesis to guide various aspects of prosody modeling, enabling applications such as AI-powered movie dubbing

* Visiting Researcher, Speech and Machine Learning Lab, Oct 2022 - Mar 2023
  * Center for Robust Speech Systems, University of Texas at Dallas
  * Research topic: multi-modal speech synthesis
  * Supervisor: Prof. Berrak Sisman
  * Conducted in-depth study of self-supervised learning speech models in speech synthesis applications, including voice conversion and text-to-speech synthesis; Proposed a novel multi-modal speech synthesis method leveraging self-supervised learning speech units, achieving remarkable performance for Automatic Voice Over

Skills
======
* Programming Languages
  * Python, MATLAB, Java, C++, C#
* Frameworks & Tools
  * PyTorch, TensorFlow, OpenCV, Kaldi, Three.js
  
Teaching Experience
======
  Teaching Assistant, National University of Singapore
  * EE2211 - Introduction to Machine Learning, Aug 2021 - May 2022
  * EE3801 - Data Engineering Principles, Aug 2021 - Dec 2021
  
Awards & Scholarships
======
* National University of Singapore Research Scholarship. Aug 2020
* China Scholarship Council Scholarship, Jun 2017
* World Rank 28/2114 in IEEEXtreme Programming Competition 10.0, Oct 2016
